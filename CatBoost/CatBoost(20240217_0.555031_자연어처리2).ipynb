{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "46319af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: catboost in ./.local/lib/python3.10/site-packages (1.2.2)\n",
      "Requirement already satisfied: six in ./.local/lib/python3.10/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in ./.local/lib/python3.10/site-packages (from catboost) (3.8.2)\n",
      "Requirement already satisfied: plotly in ./.local/lib/python3.10/site-packages (from catboost) (5.18.0)\n",
      "Requirement already satisfied: graphviz in ./.local/lib/python3.10/site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in ./.local/lib/python3.10/site-packages (from catboost) (1.23.5)\n",
      "Requirement already satisfied: pandas>=0.24 in ./.local/lib/python3.10/site-packages (from catboost) (2.1.4)\n",
      "Requirement already satisfied: scipy in ./.local/lib/python3.10/site-packages (from catboost) (1.11.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.local/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.local/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.local/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2023.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (3.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (10.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (1.4.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (4.47.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in ./.local/lib/python3.10/site-packages (from plotly->catboost) (8.2.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0fce2ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: catboost in ./.local/lib/python3.10/site-packages (1.2.2)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-2.3.1-py3-none-any.whl (132 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in ./.local/lib/python3.10/site-packages (from catboost) (1.23.5)\n",
      "Requirement already satisfied: pandas>=0.24 in ./.local/lib/python3.10/site-packages (from catboost) (2.1.4)\n",
      "Requirement already satisfied: six in ./.local/lib/python3.10/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: plotly in ./.local/lib/python3.10/site-packages (from catboost) (5.18.0)\n",
      "Requirement already satisfied: matplotlib in ./.local/lib/python3.10/site-packages (from catboost) (3.8.2)\n",
      "Requirement already satisfied: scipy in ./.local/lib/python3.10/site-packages (from catboost) (1.11.4)\n",
      "Requirement already satisfied: graphviz in ./.local/lib/python3.10/site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: tqdm in ./.local/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\n",
      "Requirement already satisfied: scikit-learn in ./.local/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.15.1 in ./.local/lib/python3.10/site-packages (from sentence-transformers) (0.20.2)\n",
      "Requirement already satisfied: Pillow in ./.local/lib/python3.10/site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./.local/lib/python3.10/site-packages (from sentence-transformers) (2.1.1+cpu)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in ./.local/lib/python3.10/site-packages (from sentence-transformers) (4.36.2)\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.4.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.12.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.9.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.local/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2023.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.local/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.local/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.0)\n",
      "Requirement already satisfied: sympy in ./.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: jinja2 in ./.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.1)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (1.4.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (4.47.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (3.1.1)\n",
      "Requirement already satisfied: joblib in ./.local/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.3.2)\n",
      "Collecting click\n",
      "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tenacity>=6.2.0 in ./.local/lib/python3.10/site-packages (from plotly->catboost) (8.2.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.local/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.local/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2023.11.17)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.local/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Installing collected packages: sentencepiece, click, nltk, sentence-transformers\n",
      "Successfully installed click-8.1.7 nltk-3.8.1 sentence-transformers-2.3.1 sentencepiece-0.1.99\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c1f920a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1b41b7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    classification_report\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6f0248cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train.csv\") # 학습용 데이터\n",
    "df_test = pd.read_csv(\"submission.csv\") # 테스트 데이터(제출파일의 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fa11d84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 처리\n",
    "text_columns = [\"customer_type\", \"customer_job\", \"inquiry_type\", \"product_category\",\n",
    "                \"product_subcategory\", \"product_modelname\", \"customer_position\",\n",
    "                \"response_corporate\", \"expected_timeline\", \"business_area\"]\n",
    "\n",
    "df_train[text_columns] = df_train[text_columns].fillna('')\n",
    "df_test[text_columns] = df_test[text_columns].fillna('')\n",
    "\n",
    "# 자연어 데이터 통합\n",
    "df_train['text_data'] = df_train[text_columns].astype(str).apply(lambda x: ' '.join(x), axis=1)\n",
    "df_test['text_data'] = df_test[text_columns].astype(str).apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4b940f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "modules.json: 100%|██████████| 229/229 [00:00<00:00, 563kB/s]\n",
      "config_sentence_transformers.json: 100%|██████████| 122/122 [00:00<00:00, 251kB/s]\n",
      "README.md: 100%|██████████| 3.73k/3.73k [00:00<00:00, 8.15MB/s]\n",
      "sentence_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 108kB/s]\n",
      "config.json: 100%|██████████| 629/629 [00:00<00:00, 1.39MB/s]\n",
      "pytorch_model.bin: 100%|██████████| 90.9M/90.9M [00:00<00:00, 131MB/s] \n",
      "tokenizer_config.json: 100%|██████████| 314/314 [00:00<00:00, 1.11MB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 1.24MB/s]\n",
      "tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 1.23MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 244kB/s]\n",
      "1_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 704kB/s]\n"
     ]
    }
   ],
   "source": [
    "# 미리 훈련된 sentence transformer 모델 로드\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5140b369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 데이터에 대한 토큰화 및 임베딩 생성\n",
    "def create_embeddings(sentences):\n",
    "    return model.encode(sentences, convert_to_tensor=True)\n",
    "\n",
    "# 결측치를 유사도를 사용하여 채우는 함수\n",
    "def fill_missing_with_similarity(df, text_column):\n",
    "    # 결측치와 결측치가 아닌 값으로 행 분리\n",
    "    missing_rows = df[df[text_column].isnull()]\n",
    "    non_missing_rows = df.dropna(subset=[text_column])\n",
    "\n",
    "    # 결측치가 아닌 값에 대한 임베딩 생성\n",
    "    embeddings = create_embeddings(non_missing_rows[text_column].tolist())\n",
    "\n",
    "    # 결측치가 있는 행을 반복하고 가장 유사한 결측치가 없는 값을 사용하여 채우기\n",
    "    for index, missing_row in missing_rows.iterrows():\n",
    "        missing_embedding = create_embeddings([missing_row[text_column]])[0]\n",
    "        similarities = cosine_similarity([missing_embedding], embeddings)[0]\n",
    "        most_similar_index = similarities.argmax()\n",
    "\n",
    "        # 결측치를 가장 유사한 결측치가 없는 값으로 채우기\n",
    "        df.at[index, text_column] = non_missing_rows.iloc[most_similar_index][text_column]\n",
    "\n",
    "# 'text_data' 열에서 결측치를 채우기 위해 함수 적용\n",
    "fill_missing_with_similarity(df_train, 'text_data')\n",
    "fill_missing_with_similarity(df_test, 'text_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5b497b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF 변환\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(df_train['text_data'])\n",
    "tfidf_test = tfidf_vectorizer.transform(df_test['text_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d0ea8c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TruncatedSVD를 사용하여 차원 축소\n",
    "svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "svd_train = svd.fit_transform(tfidf_train)\n",
    "svd_test = svd.transform(tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1ced595b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변환된 데이터를 데이터프레임에 추가\n",
    "df_svd_train = pd.DataFrame(svd_train, columns=[f'svd_{i}' for i in range(svd_train.shape[1])])\n",
    "df_svd_test = pd.DataFrame(svd_test, columns=[f'svd_{i}' for i in range(svd_test.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "643ab894",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_train, df_svd_train], axis=1)\n",
    "df_test = pd.concat([df_test, df_svd_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d5239b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원래의 텍스트 열 및 중간 열들 삭제\n",
    "df_train.drop(text_columns + ['text_data'], axis=1, inplace=True)\n",
    "df_test.drop(text_columns + ['text_data'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1b0ad906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수치형 변수 전체 Standardization, Normalization 실행\n",
    "scaler_standard = StandardScaler()\n",
    "scaler_minmax = MinMaxScaler()\n",
    "columns_to_ST = [\"com_reg_ver_win_rate\", \"historical_existing_cnt\", \"lead_desc_length\"]\n",
    "columns_to_NM = [\"ver_win_rate_x\", \"ver_win_ratio_per_bu\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3243d9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Standardization to each column\n",
    "for column in columns_to_ST:\n",
    "    df_train[column + '_standardized'] = scaler_standard.fit_transform(df_train[[column]])\n",
    "    df_test[column + '_standardized'] = scaler_standard.transform(df_test[[column]])\n",
    "    df_train.drop(columns=[column], inplace=True)\n",
    "    df_test.drop(columns=[column], inplace=True)\n",
    "\n",
    "# Apply Normalization to each column\n",
    "for column in columns_to_NM:\n",
    "    df_train[column + '_normalized'] = scaler_minmax.fit_transform(df_train[[column]])\n",
    "    df_test[column + '_normalized'] = scaler_minmax.transform(df_test[[column]])\n",
    "    df_train.drop(columns=[column], inplace=True)\n",
    "    df_test.drop(columns=[column], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "122b5daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터와 검증 데이터로 분할\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    df_train.drop(\"is_converted\", axis=1),\n",
    "    df_train[\"is_converted\"],\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=400,\n",
    ")\n",
    "\n",
    "cat_features_col = list(x_train.columns)\n",
    "cat_features_col.remove(\"bant_submit\")\n",
    "cat_features_col.remove(\"com_reg_ver_win_rate_standardized\")\n",
    "cat_features_col.remove(\"historical_existing_cnt_standardized\")\n",
    "cat_features_col.remove(\"id_strategic_ver\")\n",
    "cat_features_col.remove(\"it_strategic_ver\")\n",
    "cat_features_col.remove(\"idit_strategic_ver\")\n",
    "cat_features_col.remove(\"lead_desc_length_standardized\")\n",
    "cat_features_col.remove(\"ver_cus\")\n",
    "cat_features_col.remove(\"ver_pro\")\n",
    "cat_features_col.remove(\"ver_win_rate_x_normalized\")\n",
    "cat_features_col.remove(\"ver_win_ratio_per_bu_normalized\")\n",
    "\n",
    "for i in range(50):\n",
    "  cat_features_col.remove(\"svd_\"+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dd54a637",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_model = CatBoostClassifier(\n",
    "    verbose=0,\n",
    "    iterations=1000,\n",
    "    depth=6,\n",
    "    learning_rate=0.1,\n",
    "    loss_function='Logloss',\n",
    "    one_hot_max_size=5,\n",
    "    cat_features=cat_features_col\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ef9a5746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the most frequent value (mode) for each column\n",
    "modes = x_train.mode().iloc[0]\n",
    "\n",
    "# Fill missing (NA) values with the mode\n",
    "x_train.fillna(modes, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "91e4ab5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fb3ac2d4220>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catboost_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d25ddcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the most frequent value (mode) for each column\n",
    "modes = x_val.mode().iloc[0]\n",
    "\n",
    "# Fill missing (NA) values with the mode\n",
    "x_val.fillna(modes, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4141b3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.99      0.99     10913\n",
      "        True       0.92      0.79      0.85       947\n",
      "\n",
      "    accuracy                           0.98     11860\n",
      "   macro avg       0.95      0.89      0.92     11860\n",
      "weighted avg       0.98      0.98      0.98     11860\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  750   197]\n",
      " [   67 10846]]\n",
      "\n",
      "Accuracy: 0.9777\n",
      "Precision: 0.9180\n",
      "Recall: 0.7920\n",
      "F1 Score: 0.8503\n"
     ]
    }
   ],
   "source": [
    "# 검증 데이터에 대한 예측 및 성능 평가\n",
    "y_val_pred = catboost_model.predict(x_val)\n",
    "y_val_pred = np.array([True if pred == 'True' else False for pred in y_val_pred])\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_val_pred, labels=[True, False]))\n",
    "print(\"\\nAccuracy: {:.4f}\".format(accuracy_score(y_val, y_val_pred)))\n",
    "print(\"Precision: {:.4f}\".format(precision_score(y_val, y_val_pred, labels=[True, False])))\n",
    "print(\"Recall: {:.4f}\".format(recall_score(y_val, y_val_pred)))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_score(y_val, y_val_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f6342480",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df_test.drop([\"is_converted\", \"id\"], axis=1)\n",
    "\n",
    "# Calculate the most frequent value (mode) for each column\n",
    "modes = x_test.mode().iloc[0]\n",
    "\n",
    "# Fill missing (NA) values with the mode\n",
    "x_test.fillna(modes, inplace=True)\n",
    "\n",
    "test_pred = catboost_model.predict(x_test)\n",
    "\n",
    "df_sub = pd.read_csv(\"submission.csv\")\n",
    "df_sub[\"is_converted\"] = test_pred\n",
    "\n",
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

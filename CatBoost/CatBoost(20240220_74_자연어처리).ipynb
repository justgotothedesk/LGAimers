{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gu1HtHgRwSIy",
        "outputId": "66d6fda8-b699-4d68-b813-aea9075e8a6f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.2-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Installing collected packages: catboost\n",
            "Successfully installed catboost-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQdlE23LDJNb",
        "outputId": "479a0233-9143-40cf-da03-9f3bc62de0b2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-2.3.1-py3-none-any.whl (132 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/132.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m122.9/132.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.8/132.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (3.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.1.99)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Installing collected packages: sentence-transformers\n",
            "Successfully installed sentence-transformers-2.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "XfvhJp4IDQIK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    classification_report\n",
        ")"
      ],
      "metadata": {
        "id": "oVy1MoPyo1u9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "train_file_path = '/content/drive/MyDrive/LGdata/train.csv'\n",
        "test_file_path = '/content/drive/MyDrive/LGdata/submission.csv'\n",
        "df_train = pd.read_csv(train_file_path)\n",
        "df_test = pd.read_csv(test_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jJM6SWZo9Ft",
        "outputId": "090e5465-3709-4eb5-8740-ccefc1569aa4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drop_col = ['customer_country.1', 'customer_country', 'id_strategic_ver', 'it_strategic_ver', 'idit_strategic_ver']\n",
        "df_train.drop(drop_col, axis=1, inplace=True)\n",
        "df_test.drop(drop_col, axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "ZbRFttdYDgy5"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# 수치형 변수 전체 Standardizaiton, Normalization 실행\n",
        "'''\n",
        "# Initialize scalers\n",
        "scaler_standard = StandardScaler()\n",
        "scaler_minmax = MinMaxScaler()\n",
        "columns_to_ST = [\"com_reg_ver_win_rate\", \"historical_existing_cnt\",\"lead_desc_length\"]\n",
        "columns_to_NM = [\"ver_win_rate_x\", \"ver_win_ratio_per_bu\"]\n",
        "\n",
        "# Apply Standardization to each column\n",
        "for column in columns_to_ST:\n",
        "    # Standardization\n",
        "    df_train[column + '_standardized'] = scaler_standard.fit_transform(df_train[[column]])\n",
        "    df_test[column + '_standardized'] = scaler_standard.fit_transform(df_test[[column]])\n",
        "    # Drop the original column\n",
        "    df_train.drop(columns=[column], inplace=True)\n",
        "    df_test.drop(columns=[column], inplace=True)\n",
        "\n",
        "# Apply Standardization to each column\n",
        "for column in columns_to_NM:\n",
        "    # Normalization\n",
        "    df_train[column + '_normalized'] = scaler_minmax.fit_transform(df_train[[column]])\n",
        "    df_test[column + '_normalized'] = scaler_minmax.fit_transform(df_test[[column]])\n",
        "    # Drop the original column\n",
        "    df_train.drop(columns=[column], inplace=True)\n",
        "    df_test.drop(columns=[column], inplace=True)"
      ],
      "metadata": {
        "id": "kgxY-SqBGp_k"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# business_area 날리고 2개 피처 추가\n",
        "'''\n",
        "def is_hospital(value):\n",
        "    if value == \"hospital & health care\":\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def is_power(value):\n",
        "    if value == \"power plant / renewable energy\":\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# \"business_area\" 열에서 함수를 적용하여 새로운 열 생성\n",
        "df_train['is_hospital'] = df_train['business_area'].apply(is_hospital)\n",
        "df_train['is_power'] = df_train['business_area'].apply(is_hospital)\n",
        "df_test['is_hospital'] = df_test['business_area'].apply(is_hospital)\n",
        "df_test['is_power'] = df_test['business_area'].apply(is_hospital)\n",
        "\n",
        "#df_train.drop(columns=[\"business_area\"], inplace=True)\n",
        "#df_test.drop(columns=[\"business_area\"], inplace=True)"
      ],
      "metadata": {
        "id": "tWsDGPoFG3PX"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# expected_timeline 에서 특정 단어 필터링\n",
        "'''\n",
        "# 새로운 열을 추가하기 위한 함수 정의\n",
        "def contains_budget(value):\n",
        "    if 'budget' in str(value).lower():  # 대소문자 구분없이 'budget'이 포함되어 있는지 확인\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# \"expected_timeline\" 열에서 함수를 적용하여 새로운 열 생성\n",
        "df_train['contains_budget'] = df_train['expected_timeline'].apply(contains_budget)\n",
        "df_test['contains_budget'] = df_test['expected_timeline'].apply(contains_budget)\n",
        "\n",
        "# 새로운 열을 추가하기 위한 함수 정의\n",
        "def contains_etc(value):\n",
        "    if 'etc' in str(value).lower():  # 대소문자 구분없이 'budget'이 포함되어 있는지 확인\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# \"expected_timeline\" 열에서 함수를 적용하여 새로운 열 생성\n",
        "df_train['contains_etc'] = df_train['expected_timeline'].apply(contains_etc)\n",
        "df_test['contains_etc'] = df_test['expected_timeline'].apply(contains_etc)\n",
        "\n",
        "# 새로운 열을 추가하기 위한 함수 정의\n",
        "def contains_hence(value):\n",
        "    if 'hence' in str(value).lower():  # 대소문자 구분없이 'budget'이 포함되어 있는지 확인\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# \"expected_timeline\" 열에서 함수를 적용하여 새로운 열 생성\n",
        "df_train['contains_hence'] = df_train['expected_timeline'].apply(contains_hence)\n",
        "df_test['contains_hence'] = df_test['expected_timeline'].apply(contains_hence)\n",
        "\n",
        "# 새로운 열을 추가하기 위한 함수 정의\n",
        "def contains_although(value):\n",
        "    if 'although' in str(value).lower():  # 대소문자 구분없이 'budget'이 포함되어 있는지 확인\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# \"expected_timeline\" 열에서 함수를 적용하여 새로운 열 생성\n",
        "df_train['contains_although'] = df_train['expected_timeline'].apply(contains_although)\n",
        "df_test['contains_although'] = df_test['expected_timeline'].apply(contains_although)\n",
        "\n",
        "# 새로운 열을 추가하기 위한 함수 정의\n",
        "def contains_more(value):\n",
        "    if 'more' in str(value).lower():  # 대소문자 구분없이 'budget'이 포함되어 있는지 확인\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# \"expected_timeline\" 열에서 함수를 적용하여 새로운 열 생성\n",
        "df_train['contains_more'] = df_train['expected_timeline'].apply(contains_more)\n",
        "df_test['contains_more'] = df_test['expected_timeline'].apply(contains_more)\n",
        "\n",
        "# 새로운 열을 추가하기 위한 함수 정의\n",
        "def contains_year(value):\n",
        "    if 'year' in str(value).lower():  # 대소문자 구분없이 'budget'이 포함되어 있는지 확인\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# \"expected_timeline\" 열에서 함수를 적용하여 새로운 열 생성\n",
        "df_train['contains_year'] = df_train['expected_timeline'].apply(contains_year)\n",
        "df_test['contains_year'] = df_test['expected_timeline'].apply(contains_year)"
      ],
      "metadata": {
        "id": "-IWa_D09G7uQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 처리\n",
        "text_columns = [\"customer_type\", \"customer_job\", \"inquiry_type\", \"product_category\",\n",
        "                \"product_subcategory\", \"product_modelname\", \"customer_position\",\n",
        "                \"response_corporate\", \"expected_timeline\", \"business_area\"]\n",
        "\n",
        "df_train[text_columns] = df_train[text_columns].fillna('')\n",
        "df_test[text_columns] = df_test[text_columns].fillna('')\n",
        "\n",
        "# 자연어 데이터 통합\n",
        "df_train['text_data'] = df_train[text_columns].astype(str).apply(lambda x: ' '.join(x), axis=1)\n",
        "df_test['text_data'] = df_test[text_columns].astype(str).apply(lambda x: ' '.join(x), axis=1)"
      ],
      "metadata": {
        "id": "aqoslj4TG83d"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "ivZBgxmsDnTe"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 텍스트 데이터에 대한 토큰화 및 임베딩 생성\n",
        "def create_embeddings(sentences):\n",
        "    return model.encode(sentences, convert_to_tensor=True)\n",
        "\n",
        "# 결측치를 유사도를 사용하여 채우는 함수\n",
        "def fill_missing_with_similarity(df, text_column):\n",
        "    # 결측치와 결측치가 아닌 값으로 행 분리\n",
        "    missing_rows = df[df[text_column].isnull()]\n",
        "    non_missing_rows = df.dropna(subset=[text_column])\n",
        "\n",
        "    # 결측치가 아닌 값에 대한 임베딩 생성\n",
        "    embeddings = create_embeddings(non_missing_rows[text_column].tolist())\n",
        "\n",
        "    # 결측치가 있는 행을 반복하고 가장 유사한 결측치가 없는 값을 사용하여 채우기\n",
        "    for index, missing_row in missing_rows.iterrows():\n",
        "        missing_embedding = create_embeddings([missing_row[text_column]])[0]\n",
        "        similarities = cosine_similarity([missing_embedding], embeddings)[0]\n",
        "        most_similar_index = similarities.argmax()\n",
        "\n",
        "        # 결측치를 가장 유사한 결측치가 없는 값으로 채우기\n",
        "        df.at[index, text_column] = non_missing_rows.iloc[most_similar_index][text_column]\n",
        "\n",
        "# 'text_data' 열에서 결측치를 채우기 위해 함수 적용\n",
        "fill_missing_with_similarity(df_train, 'text_data')\n",
        "fill_missing_with_similarity(df_test, 'text_data')"
      ],
      "metadata": {
        "id": "TbP_CPXS5koa"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF 변환\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
        "tfidf_train = tfidf_vectorizer.fit_transform(df_train['text_data'])\n",
        "tfidf_test = tfidf_vectorizer.transform(df_test['text_data'])"
      ],
      "metadata": {
        "id": "_w_QP08dyM0Q"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TruncatedSVD를 사용하여 차원 축소\n",
        "svd = TruncatedSVD(n_components=50, random_state=42)\n",
        "svd_train = svd.fit_transform(tfidf_train)\n",
        "svd_test = svd.transform(tfidf_test)"
      ],
      "metadata": {
        "id": "WiGvu6tEyOUI"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 변환된 데이터를 데이터프레임에 추가\n",
        "df_svd_train = pd.DataFrame(svd_train, columns=[f'svd_{i}' for i in range(svd_train.shape[1])])\n",
        "df_svd_test = pd.DataFrame(svd_test, columns=[f'svd_{i}' for i in range(svd_test.shape[1])])"
      ],
      "metadata": {
        "id": "Wz8vjqZWyRK2"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.concat([df_train, df_svd_train], axis=1)\n",
        "df_test = pd.concat([df_test, df_svd_test], axis=1)"
      ],
      "metadata": {
        "id": "ajpjSEerySsQ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 원래의 텍스트 열 및 중간 열들 삭제\n",
        "df_train.drop(text_columns + ['text_data'], axis=1, inplace=True)\n",
        "df_test.drop(text_columns + ['text_data'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "K0Uq_qBPyVGp"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 데이터와 검증 데이터로 분할\n",
        "x_train, x_val, y_train, y_val = train_test_split(\n",
        "    df_train.drop(\"is_converted\", axis=1),\n",
        "    df_train[\"is_converted\"],\n",
        "    test_size=0.2,\n",
        "    shuffle=True,\n",
        "    random_state=400,\n",
        ")\n",
        "\n",
        "cat_features_col = list(x_train.columns)\n",
        "cat_features_col.remove(\"bant_submit\")\n",
        "cat_features_col.remove(\"com_reg_ver_win_rate_standardized\")\n",
        "cat_features_col.remove(\"historical_existing_cnt_standardized\")\n",
        "cat_features_col.remove(\"lead_desc_length_standardized\")\n",
        "cat_features_col.remove(\"ver_cus\")\n",
        "cat_features_col.remove(\"ver_pro\")\n",
        "cat_features_col.remove(\"ver_win_rate_x_normalized\")\n",
        "cat_features_col.remove(\"ver_win_ratio_per_bu_normalized\")\n",
        "\n",
        "for i in range(50):\n",
        "  cat_features_col.remove(\"svd_\"+str(i))"
      ],
      "metadata": {
        "id": "jm4NaiptyatD"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "catboost_model = CatBoostClassifier(\n",
        "    verbose=0,\n",
        "    iterations=1000,\n",
        "    depth=6,\n",
        "    learning_rate=0.1,\n",
        "    loss_function='Logloss',\n",
        "    one_hot_max_size=5,\n",
        "    cat_features=cat_features_col\n",
        ")"
      ],
      "metadata": {
        "id": "O_F32HRMycIK"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the most frequent value (mode) for each column\n",
        "modes = x_train.mode().iloc[0]\n",
        "\n",
        "# Fill missing (NA) values with the mode\n",
        "x_train.fillna(modes, inplace=True)"
      ],
      "metadata": {
        "id": "dVurroLWyyPw"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "catboost_model.fit(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsNdkIvUyhcx",
        "outputId": "cf991c5c-a2e7-4086-bd88-996f630ff2da"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7c0009909ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the most frequent value (mode) for each column\n",
        "modes = x_val.mode().iloc[0]\n",
        "\n",
        "# Fill missing (NA) values with the mode\n",
        "x_val.fillna(modes, inplace=True)"
      ],
      "metadata": {
        "id": "mhYewFXA0Hxb"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 검증 데이터에 대한 예측 및 성능 평가\n",
        "y_val_pred = catboost_model.predict(x_val)\n",
        "y_val_pred = np.array([True if pred == 'True' else False for pred in y_val_pred])\n",
        "\n",
        "print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_val_pred, labels=[True, False]))\n",
        "print(\"\\nAccuracy: {:.4f}\".format(accuracy_score(y_val, y_val_pred)))\n",
        "print(\"Precision: {:.4f}\".format(precision_score(y_val, y_val_pred, labels=[True, False])))\n",
        "print(\"Recall: {:.4f}\".format(recall_score(y_val, y_val_pred)))\n",
        "print(\"F1 Score: {:.4f}\".format(f1_score(y_val, y_val_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbdCS2bWy31K",
        "outputId": "7337cf52-9581-4a9c-ed43-f9c2e404f9c2"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.98      0.99      0.99     10913\n",
            "        True       0.92      0.79      0.85       947\n",
            "\n",
            "    accuracy                           0.98     11860\n",
            "   macro avg       0.95      0.89      0.92     11860\n",
            "weighted avg       0.98      0.98      0.98     11860\n",
            "\n",
            "Confusion Matrix:\n",
            " [[  745   202]\n",
            " [   66 10847]]\n",
            "\n",
            "Accuracy: 0.9774\n",
            "Precision: 0.9186\n",
            "Recall: 0.7867\n",
            "F1 Score: 0.8476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 데이터에 대한 예측 및 결과 저장\n",
        "x_test = df_test.drop([\"is_converted\", \"id\"], axis=1)\n",
        "test_pred = catboost_model.predict(x_test)\n",
        "df_sub = pd.read_csv(\"submission.csv\")\n",
        "df_sub[\"is_converted\"] = test_pred\n",
        "df_sub.to_csv(\"submission.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        },
        "id": "3OZtU2bdYGNO",
        "outputId": "7a1d373a-1941-4c4d-bfac-5ac32fc7da6e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "CatBoostError",
          "evalue": "Invalid type for cat_feature[non-default value idx=6,feature_idx=1]=nan : cat_features must be integer or string, real number values and NaN values should be converted to string.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost.get_cat_factor_bytes_representation\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost.get_id_object_bytes_string_representation\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mCatBoostError\u001b[0m: bad object for id: nan",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-0a4775a1bccc>\u001b[0m in \u001b[0;36m<cell line: 86>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m )\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m \u001b[0mcatboost_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;31m# 검증 데이터에 대한 예측 및 성능 평가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5098\u001b[0m             \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_compatible_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5100\u001b[0;31m         self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[0m\u001b[1;32m   5101\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5102\u001b[0m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2301\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCatBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y may be None only when X is an instance of catboost.Pool or string\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2303\u001b[0;31m         train_params = self._prepare_train_params(\n\u001b[0m\u001b[1;32m   2304\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2305\u001b[0m             \u001b[0mpairs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_prepare_train_params\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks)\u001b[0m\n\u001b[1;32m   2182\u001b[0m         \u001b[0membedding_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_feature_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'embedding_features'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2184\u001b[0;31m         train_pool = _build_train_pool(X, y, cat_features, text_features, embedding_features, pairs,\n\u001b[0m\u001b[1;32m   2185\u001b[0m                                        \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2186\u001b[0m                                        baseline, column_description)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_build_train_pool\u001b[0;34m(X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, column_description)\u001b[0m\n\u001b[1;32m   1442\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCatBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y has not initialized in fit(): X is not catboost.Pool object, y must be not None in fit().\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m         train_pool = Pool(X, y, cat_features=cat_features, text_features=text_features, embedding_features=embedding_features, pairs=pairs, weight=sample_weight, group_id=group_id,\n\u001b[0m\u001b[1;32m   1445\u001b[0m                           group_weight=group_weight, subgroup_id=subgroup_id, pairs_weight=pairs_weight, baseline=baseline)\n\u001b[1;32m   1446\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, column_description, pairs, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m    791\u001b[0m                     )\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 793\u001b[0;31m                 self._init(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n\u001b[0m\u001b[1;32m    794\u001b[0m                            group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\n\u001b[1;32m    795\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/catboost/core.py\u001b[0m in \u001b[0;36m_init\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\u001b[0m\n\u001b[1;32m   1423\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeature_tags\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m             \u001b[0mfeature_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_transform_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m         self._init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n\u001b[0m\u001b[1;32m   1426\u001b[0m                         group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\n\u001b[1;32m   1427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._PoolBase._init_features_order_layout_pool\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._set_features_order_data_pd_data_frame\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost.get_cat_factor_bytes_representation\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mCatBoostError\u001b[0m: Invalid type for cat_feature[non-default value idx=6,feature_idx=1]=nan : cat_features must be integer or string, real number values and NaN values should be converted to string."
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
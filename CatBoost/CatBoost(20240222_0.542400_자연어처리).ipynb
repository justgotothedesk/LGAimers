{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c20d374f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: catboost in ./.local/lib/python3.10/site-packages (1.2.2)\n",
      "Requirement already satisfied: plotly in ./.local/lib/python3.10/site-packages (from catboost) (5.18.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in ./.local/lib/python3.10/site-packages (from catboost) (1.23.5)\n",
      "Requirement already satisfied: pandas>=0.24 in ./.local/lib/python3.10/site-packages (from catboost) (2.1.4)\n",
      "Requirement already satisfied: matplotlib in ./.local/lib/python3.10/site-packages (from catboost) (3.8.2)\n",
      "Requirement already satisfied: six in ./.local/lib/python3.10/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: scipy in ./.local/lib/python3.10/site-packages (from catboost) (1.11.4)\n",
      "Requirement already satisfied: graphviz in ./.local/lib/python3.10/site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.local/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2023.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.local/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.local/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pillow>=8 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (3.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (1.4.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (4.47.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (23.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in ./.local/lib/python3.10/site-packages (from plotly->catboost) (8.2.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d466ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: catboost in ./.local/lib/python3.10/site-packages (1.2.2)\n",
      "Requirement already satisfied: sentence-transformers in ./.local/lib/python3.10/site-packages (2.3.1)\n",
      "Requirement already satisfied: graphviz in ./.local/lib/python3.10/site-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: plotly in ./.local/lib/python3.10/site-packages (from catboost) (5.18.0)\n",
      "Requirement already satisfied: pandas>=0.24 in ./.local/lib/python3.10/site-packages (from catboost) (2.1.4)\n",
      "Requirement already satisfied: scipy in ./.local/lib/python3.10/site-packages (from catboost) (1.11.4)\n",
      "Requirement already satisfied: matplotlib in ./.local/lib/python3.10/site-packages (from catboost) (3.8.2)\n",
      "Requirement already satisfied: six in ./.local/lib/python3.10/site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in ./.local/lib/python3.10/site-packages (from catboost) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn in ./.local/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: sentencepiece in ./.local/lib/python3.10/site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./.local/lib/python3.10/site-packages (from sentence-transformers) (2.1.1+cpu)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in ./.local/lib/python3.10/site-packages (from sentence-transformers) (4.36.2)\n",
      "Requirement already satisfied: tqdm in ./.local/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\n",
      "Requirement already satisfied: Pillow in ./.local/lib/python3.10/site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: nltk in ./.local/lib/python3.10/site-packages (from sentence-transformers) (3.8.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in ./.local/lib/python3.10/site-packages (from sentence-transformers) (0.20.2)\n",
      "Requirement already satisfied: filelock in ./.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.4.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.12.2)\n",
      "Requirement already satisfied: requests in ./.local/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.local/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.local/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2023.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.local/lib/python3.10/site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: networkx in ./.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.0)\n",
      "Requirement already satisfied: sympy in ./.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: jinja2 in ./.local/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./.local/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (1.4.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (4.47.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.local/lib/python3.10/site-packages (from matplotlib->catboost) (3.1.1)\n",
      "Requirement already satisfied: joblib in ./.local/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: click in ./.local/lib/python3.10/site-packages (from nltk->sentence-transformers) (8.1.7)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in ./.local/lib/python3.10/site-packages (from plotly->catboost) (8.2.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.local/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.local/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.local/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.local/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a97c9c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78e9f422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    classification_report\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b74e5045",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train.csv\") # 학습용 데이터\n",
    "df_test = pd.read_csv(\"submission.csv\") # 테스트 데이터(제출파일의 데이터)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac398979",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col = ['customer_country.1', 'customer_country', 'id_strategic_ver', 'it_strategic_ver', 'idit_strategic_ver']\n",
    "df_train.drop(drop_col, axis=1, inplace=True)\n",
    "df_test.drop(drop_col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3581014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# 수치형 변수 전체 Standardizaiton, Normalization 실행\n",
    "'''\n",
    "# Initialize scalers\n",
    "scaler_standard = StandardScaler()\n",
    "scaler_minmax = MinMaxScaler()\n",
    "columns_to_ST = [\"com_reg_ver_win_rate\", \"historical_existing_cnt\",\"lead_desc_length\"]\n",
    "columns_to_NM = [\"ver_win_rate_x\", \"ver_win_ratio_per_bu\"]\n",
    "\n",
    "# Apply Standardization to each column\n",
    "for column in columns_to_ST:\n",
    "    # Standardization\n",
    "    df_train[column + '_standardized'] = scaler_standard.fit_transform(df_train[[column]])\n",
    "    df_test[column + '_standardized'] = scaler_standard.fit_transform(df_test[[column]])\n",
    "    # Drop the original column\n",
    "    df_train.drop(columns=[column], inplace=True)\n",
    "    df_test.drop(columns=[column], inplace=True)\n",
    "\n",
    "# Apply Standardization to each column\n",
    "for column in columns_to_NM:\n",
    "    # Normalization\n",
    "    df_train[column + '_normalized'] = scaler_minmax.fit_transform(df_train[[column]])\n",
    "    df_test[column + '_normalized'] = scaler_minmax.fit_transform(df_test[[column]])\n",
    "    # Drop the original column\n",
    "    df_train.drop(columns=[column], inplace=True)\n",
    "    df_test.drop(columns=[column], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a96211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# business_area 날리고 2개 피처 추가\n",
    "'''\n",
    "def is_hospital(value):\n",
    "    if value == \"hospital & health care\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def is_power(value):\n",
    "    if value == \"power plant / renewable energy\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# \"business_area\" 열에서 함수를 적용하여 새로운 열 생성\n",
    "df_train['is_hospital'] = df_train['business_area'].apply(is_hospital)\n",
    "df_train['is_power'] = df_train['business_area'].apply(is_hospital)\n",
    "df_test['is_hospital'] = df_test['business_area'].apply(is_hospital)\n",
    "df_test['is_power'] = df_test['business_area'].apply(is_hospital)\n",
    "\n",
    "#df_train.drop(columns=[\"business_area\"], inplace=True)\n",
    "#df_test.drop(columns=[\"business_area\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc9232c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# expected_timeline 에서 특정 단어 필터링\n",
    "'''\n",
    "# 새로운 열을 추가하기 위한 함수 정의\n",
    "def contains_budget(value):\n",
    "    if 'budget' in str(value).lower():  # 대소문자 구분없이 'budget'이 포함되어 있는지 확인\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# \"expected_timeline\" 열에서 함수를 적용하여 새로운 열 생성\n",
    "df_train['contains_budget'] = df_train['expected_timeline'].apply(contains_budget)\n",
    "df_test['contains_budget'] = df_test['expected_timeline'].apply(contains_budget)\n",
    "\n",
    "# 새로운 열을 추가하기 위한 함수 정의\n",
    "def contains_etc(value):\n",
    "    if 'etc' in str(value).lower():  # 대소문자 구분없이 'budget'이 포함되어 있는지 확인\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# \"expected_timeline\" 열에서 함수를 적용하여 새로운 열 생성\n",
    "df_train['contains_etc'] = df_train['expected_timeline'].apply(contains_etc)\n",
    "df_test['contains_etc'] = df_test['expected_timeline'].apply(contains_etc)\n",
    "\n",
    "# 새로운 열을 추가하기 위한 함수 정의\n",
    "def contains_hence(value):\n",
    "    if 'hence' in str(value).lower():  # 대소문자 구분없이 'budget'이 포함되어 있는지 확인\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# \"expected_timeline\" 열에서 함수를 적용하여 새로운 열 생성\n",
    "df_train['contains_hence'] = df_train['expected_timeline'].apply(contains_hence)\n",
    "df_test['contains_hence'] = df_test['expected_timeline'].apply(contains_hence)\n",
    "\n",
    "# 새로운 열을 추가하기 위한 함수 정의\n",
    "def contains_although(value):\n",
    "    if 'although' in str(value).lower():  # 대소문자 구분없이 'budget'이 포함되어 있는지 확인\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# \"expected_timeline\" 열에서 함수를 적용하여 새로운 열 생성\n",
    "df_train['contains_although'] = df_train['expected_timeline'].apply(contains_although)\n",
    "df_test['contains_although'] = df_test['expected_timeline'].apply(contains_although)\n",
    "\n",
    "# 새로운 열을 추가하기 위한 함수 정의\n",
    "def contains_more(value):\n",
    "    if 'more' in str(value).lower():  # 대소문자 구분없이 'budget'이 포함되어 있는지 확인\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# \"expected_timeline\" 열에서 함수를 적용하여 새로운 열 생성\n",
    "df_train['contains_more'] = df_train['expected_timeline'].apply(contains_more)\n",
    "df_test['contains_more'] = df_test['expected_timeline'].apply(contains_more)\n",
    "\n",
    "# 새로운 열을 추가하기 위한 함수 정의\n",
    "def contains_year(value):\n",
    "    if 'year' in str(value).lower():  # 대소문자 구분없이 'budget'이 포함되어 있는지 확인\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# \"expected_timeline\" 열에서 함수를 적용하여 새로운 열 생성\n",
    "df_train['contains_year'] = df_train['expected_timeline'].apply(contains_year)\n",
    "df_test['contains_year'] = df_test['expected_timeline'].apply(contains_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "495d9d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치 처리\n",
    "text_columns = [\"customer_type\", \"customer_job\", \"inquiry_type\", \"product_category\",\n",
    "                \"product_subcategory\", \"product_modelname\", \"customer_position\",\n",
    "                \"response_corporate\", \"expected_timeline\", \"business_area\"]\n",
    "\n",
    "df_train[text_columns] = df_train[text_columns].fillna('')\n",
    "df_test[text_columns] = df_test[text_columns].fillna('')\n",
    "\n",
    "# 자연어 데이터 통합\n",
    "df_train['text_data'] = df_train[text_columns].astype(str).apply(lambda x: ' '.join(x), axis=1)\n",
    "df_test['text_data'] = df_test[text_columns].astype(str).apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5806d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fad91e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 데이터에 대한 토큰화 및 임베딩 생성\n",
    "def create_embeddings(sentences):\n",
    "    return model.encode(sentences, convert_to_tensor=True)\n",
    "\n",
    "# 결측치를 유사도를 사용하여 채우는 함수\n",
    "def fill_missing_with_similarity(df, text_column):\n",
    "    # 결측치와 결측치가 아닌 값으로 행 분리\n",
    "    missing_rows = df[df[text_column].isnull()]\n",
    "    non_missing_rows = df.dropna(subset=[text_column])\n",
    "\n",
    "    # 결측치가 아닌 값에 대한 임베딩 생성\n",
    "    embeddings = create_embeddings(non_missing_rows[text_column].tolist())\n",
    "\n",
    "    # 결측치가 있는 행을 반복하고 가장 유사한 결측치가 없는 값을 사용하여 채우기\n",
    "    for index, missing_row in missing_rows.iterrows():\n",
    "        missing_embedding = create_embeddings([missing_row[text_column]])[0]\n",
    "        similarities = cosine_similarity([missing_embedding], embeddings)[0]\n",
    "        most_similar_index = similarities.argmax()\n",
    "\n",
    "        # 결측치를 가장 유사한 결측치가 없는 값으로 채우기\n",
    "        df.at[index, text_column] = non_missing_rows.iloc[most_similar_index][text_column]\n",
    "\n",
    "# 'text_data' 열에서 결측치를 채우기 위해 함수 적용\n",
    "fill_missing_with_similarity(df_train, 'text_data')\n",
    "fill_missing_with_similarity(df_test, 'text_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3c3590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF 변환\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(df_train['text_data'])\n",
    "tfidf_test = tfidf_vectorizer.transform(df_test['text_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "508df52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TruncatedSVD를 사용하여 차원 축소\n",
    "svd = TruncatedSVD(n_components=50, random_state=42)\n",
    "svd_train = svd.fit_transform(tfidf_train)\n",
    "svd_test = svd.transform(tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41e686d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변환된 데이터를 데이터프레임에 추가\n",
    "df_svd_train = pd.DataFrame(svd_train, columns=[f'svd_{i}' for i in range(svd_train.shape[1])])\n",
    "df_svd_test = pd.DataFrame(svd_test, columns=[f'svd_{i}' for i in range(svd_test.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba04d868",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_train, df_svd_train], axis=1)\n",
    "df_test = pd.concat([df_test, df_svd_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1da9c8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원래의 텍스트 열 및 중간 열들 삭제\n",
    "df_train.drop(text_columns + ['text_data'], axis=1, inplace=True)\n",
    "df_test.drop(text_columns + ['text_data'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fd5498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터와 검증 데이터로 분할\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    df_train.drop(\"is_converted\", axis=1),\n",
    "    df_train[\"is_converted\"],\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=400,\n",
    ")\n",
    "\n",
    "cat_features_col = list(x_train.columns)\n",
    "cat_features_col.remove(\"bant_submit\")\n",
    "cat_features_col.remove(\"com_reg_ver_win_rate_standardized\")\n",
    "cat_features_col.remove(\"historical_existing_cnt_standardized\")\n",
    "cat_features_col.remove(\"lead_desc_length_standardized\")\n",
    "cat_features_col.remove(\"ver_cus\")\n",
    "cat_features_col.remove(\"ver_pro\")\n",
    "cat_features_col.remove(\"ver_win_rate_x_normalized\")\n",
    "cat_features_col.remove(\"ver_win_ratio_per_bu_normalized\")\n",
    "\n",
    "for i in range(50):\n",
    "  cat_features_col.remove(\"svd_\"+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0205722",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_model = CatBoostClassifier(\n",
    "    verbose=0,\n",
    "    iterations=1000,\n",
    "    depth=6,\n",
    "    learning_rate=0.1,\n",
    "    loss_function='Logloss',\n",
    "    one_hot_max_size=5,\n",
    "    cat_features=cat_features_col\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2dc7d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the most frequent value (mode) for each column\n",
    "modes = x_train.mode().iloc[0]\n",
    "\n",
    "# Fill missing (NA) values with the mode\n",
    "x_train.fillna(modes, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d71304ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fa3a4e1b9a0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catboost_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a2368f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the most frequent value (mode) for each column\n",
    "modes = x_val.mode().iloc[0]\n",
    "\n",
    "# Fill missing (NA) values with the mode\n",
    "x_val.fillna(modes, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "649decce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.99      0.99     10913\n",
      "        True       0.92      0.79      0.85       947\n",
      "\n",
      "    accuracy                           0.98     11860\n",
      "   macro avg       0.95      0.89      0.92     11860\n",
      "weighted avg       0.98      0.98      0.98     11860\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  745   202]\n",
      " [   66 10847]]\n",
      "\n",
      "Accuracy: 0.9774\n",
      "Precision: 0.9186\n",
      "Recall: 0.7867\n",
      "F1 Score: 0.8476\n"
     ]
    }
   ],
   "source": [
    "# 검증 데이터에 대한 예측 및 성능 평가\n",
    "y_val_pred = catboost_model.predict(x_val)\n",
    "y_val_pred = np.array([True if pred == 'True' else False for pred in y_val_pred])\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_val_pred, labels=[True, False]))\n",
    "print(\"\\nAccuracy: {:.4f}\".format(accuracy_score(y_val, y_val_pred)))\n",
    "print(\"Precision: {:.4f}\".format(precision_score(y_val, y_val_pred, labels=[True, False])))\n",
    "print(\"Recall: {:.4f}\".format(recall_score(y_val, y_val_pred)))\n",
    "print(\"F1 Score: {:.4f}\".format(f1_score(y_val, y_val_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3a4b2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the most frequent value (mode) for each column\n",
    "modes = df_test.mode().iloc[0]\n",
    "\n",
    "# Fill missing (NA) values with the mode\n",
    "df_test.fillna(modes, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7298d47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df_test.drop([\"is_converted\", \"id\"], axis=1)\n",
    "\n",
    "test_pred = catboost_model.predict(x_test)\n",
    "\n",
    "# 'True'를 True로, 'False'를 False로 변환\n",
    "test_pred_bool = np.array([True if pred == 'True' else False for pred in test_pred])\n",
    "\n",
    "df_sub = pd.read_csv(\"submission.csv\")\n",
    "df_sub[\"is_converted\"] = test_pred_bool\n",
    "\n",
    "# 제출 파일 저장\n",
    "df_sub.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75cebd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        True\n",
      "1        True\n",
      "2       False\n",
      "3       False\n",
      "4       False\n",
      "        ...  \n",
      "5266    False\n",
      "5267     True\n",
      "5268    False\n",
      "5269    False\n",
      "5270     True\n",
      "Name: is_converted, Length: 5271, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(df_sub['is_converted'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

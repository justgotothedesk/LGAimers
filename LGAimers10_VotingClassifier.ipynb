{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CJlFeYwwoSmm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    confusion_matrix,\n",
        "    f1_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    classification_report\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train_file_path = '/content/drive/MyDrive/LGdata/train.csv'\n",
        "test_file_path = '/content/drive/MyDrive/LGdata/submission.csv'\n",
        "\n",
        "df_train = pd.read_csv(train_file_path)\n",
        "df_test = pd.read_csv(test_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4V5zj_51ofBK",
        "outputId": "120a47ff-203a-462b-962d-ebd4ead15e9c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def label_encoding(series: pd.Series) -> pd.Series:\n",
        "    my_dict = {}\n",
        "\n",
        "    series = series.astype(str)\n",
        "\n",
        "    for idx, value in enumerate(sorted(series.unique())):\n",
        "        my_dict[value] = idx\n",
        "    series = series.map(my_dict)\n",
        "\n",
        "    return series"
      ],
      "metadata": {
        "id": "t7fN7nSRolRs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_columns = [\n",
        "    \"customer_country\",\n",
        "    \"business_subarea\",\n",
        "    \"business_area\",\n",
        "    \"business_unit\",\n",
        "    \"customer_type\",\n",
        "    \"enterprise\",\n",
        "    \"customer_job\",\n",
        "    \"inquiry_type\",\n",
        "    \"product_category\",\n",
        "    \"product_subcategory\",\n",
        "    \"product_modelname\",\n",
        "    \"customer_country.1\",\n",
        "    \"customer_position\",\n",
        "    \"response_corporate\",\n",
        "    \"expected_timeline\",\n",
        "]"
      ],
      "metadata": {
        "id": "zUnYaiJEopXq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all = pd.concat([df_train[label_columns], df_test[label_columns]])\n",
        "\n",
        "for col in label_columns:\n",
        "    df_all[col] = label_encoding(df_all[col])\n",
        "\n",
        "for col in label_columns:\n",
        "    df_train[col] = df_all.iloc[:len(df_train)][col]\n",
        "    df_test[col] = df_all.iloc[len(df_train):][col]"
      ],
      "metadata": {
        "id": "suXPaAPOorAn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(\n",
        "    df_train.drop(\"is_converted\", axis=1),\n",
        "    df_train[\"is_converted\"],\n",
        "    test_size=0.2,\n",
        "    shuffle=True,\n",
        "    random_state=400,\n",
        ")"
      ],
      "metadata": {
        "id": "Jr0wfJ2uosfm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_features = x_train.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = x_train.select_dtypes(include=['object']).columns\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])"
      ],
      "metadata": {
        "id": "hVzHkXK8ot3_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree_model = DecisionTreeClassifier(random_state=400)\n",
        "xgb_model = XGBClassifier(random_state=400)\n",
        "gb_model = GradientBoostingClassifier(random_state=400)"
      ],
      "metadata": {
        "id": "vr8zA608ovUZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VotingClassifier(estimators=[\n",
        "    ('decision_tree', tree_model),\n",
        "    ('xgboost', xgb_model),\n",
        "    ('gradient_boosting', gb_model)\n",
        "], voting='soft') # or hard\n",
        "\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                   ('classifier', model)])\n",
        "\n",
        "pipeline.fit(x_train, y_train)\n",
        "\n",
        "y_val_pred = pipeline.predict(x_val)"
      ],
      "metadata": {
        "id": "nv7ktHSCoyRm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
        "print(\"오차행렬:\\n\", confusion_matrix(y_val, y_val_pred, labels=[True, False]))\n",
        "print(\"\\n정확도: {:.4f}\".format(accuracy_score(y_val, y_val_pred)))\n",
        "print(\"정밀도: {:.4f}\".format(precision_score(y_val, y_val_pred, labels=[True, False])))\n",
        "print(\"재현율: {:.4f}\".format(recall_score(y_val, y_val_pred)))\n",
        "print(\"F1: {:.4f}\".format(f1_score(y_val, y_val_pred, labels=[True, False])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fun8nV5xo9Xe",
        "outputId": "5dab35d2-355c-4a5d-8b1e-9beba5614c34"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       False       0.98      0.99      0.99     10913\n",
            "        True       0.90      0.74      0.82       947\n",
            "\n",
            "    accuracy                           0.97     11860\n",
            "   macro avg       0.94      0.87      0.90     11860\n",
            "weighted avg       0.97      0.97      0.97     11860\n",
            "\n",
            "오차행렬:\n",
            " [[  705   242]\n",
            " [   77 10836]]\n",
            "\n",
            "정확도: 0.9731\n",
            "정밀도: 0.9015\n",
            "재현율: 0.7445\n",
            "F1: 0.8155\n"
          ]
        }
      ]
    }
  ]
}